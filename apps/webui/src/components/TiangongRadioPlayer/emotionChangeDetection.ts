/**
 * æƒ…ç»ªå˜åŒ–æ£€æµ‹ç®—æ³•
 * åŸºäºéŸ³é¢‘ç‰¹å¾å’Œç”¨æˆ·äº¤äº’æ£€æµ‹æƒ…ç»ªå˜åŒ–
 * é‡‡ç”¨ç»“æ„æ€§å¥½çš„è®¾è®¡ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
 */

import { UnifiedEventBus } from '../events/UnifiedEventBus';
import type { AudioFeatures } from '../../vis/AudioReactive';

// æƒ…ç»ªç±»å‹å®šä¹‰
export type EmotionType = 'calm' | 'energetic' | 'melancholic' | 'excited' | 'focused' | 'relaxed' | 'intense';

// æƒ…ç»ªçŠ¶æ€
export interface EmotionState {
  type: EmotionType;
  intensity: number;        // 0-1
  confidence: number;       // 0-1
  timestamp: number;
  duration: number;         // æŒç»­æ—¶é—´ (ms)
  stability: number;        // ç¨³å®šæ€§ (0-1)
}

// æƒ…ç»ªå˜åŒ–äº‹ä»¶
export interface EmotionChangeEvent {
  type: 'emotion_change';
  fromEmotion: EmotionState;
  toEmotion: EmotionState;
  changeMagnitude: number;  // å˜åŒ–å¹…åº¦ (0-1)
  confidence: number;       // å˜åŒ–ç½®ä¿¡åº¦ (0-1)
  timestamp: number;
  trigger: 'audio' | 'user' | 'time' | 'external';
  audioFeatures?: AudioFeatures;
}

// æƒ…ç»ªæ£€æµ‹é…ç½®
export interface EmotionDetectionConfig {
  // éŸ³é¢‘ç‰¹å¾æƒé‡
  audioFeatureWeights: {
    energy: number;         // èƒ½é‡æƒé‡
    flux: number;           // é€šé‡æƒé‡
    centroid: number;       // è´¨å¿ƒæƒé‡
    crest: number;          // å³°å‡æ¯”æƒé‡
    bass: number;           // ä½é¢‘æƒé‡
    presence: number;       // å­˜åœ¨æ„Ÿæƒé‡
  };
  
  // å˜åŒ–æ£€æµ‹é˜ˆå€¼
  changeThresholds: {
    intensityChange: number;    // å¼ºåº¦å˜åŒ–é˜ˆå€¼
    durationChange: number;     // æŒç»­æ—¶é—´å˜åŒ–é˜ˆå€¼
    stabilityChange: number;    // ç¨³å®šæ€§å˜åŒ–é˜ˆå€¼
    timeWindow: number;         // æ—¶é—´çª—å£ (ms)
  };
  
  // æƒ…ç»ªç‰¹å¾é…ç½®
  emotionFeatures: {
    [key in EmotionType]: {
      energyRange: [number, number];      // èƒ½é‡èŒƒå›´
      fluxRange: [number, number];        // é€šé‡èŒƒå›´
      centroidRange: [number, number];    // è´¨å¿ƒèŒƒå›´
      bassRange: [number, number];        // ä½é¢‘èŒƒå›´
      presenceRange: [number, number];    // å­˜åœ¨æ„ŸèŒƒå›´
      stabilityRange: [number, number];   // ç¨³å®šæ€§èŒƒå›´
      transitionProbability: number;       // è½¬æ¢æ¦‚ç‡
    };
  };
}

// é»˜è®¤é…ç½®
export const DEFAULT_EMOTION_DETECTION_CONFIG: EmotionDetectionConfig = {
  audioFeatureWeights: {
    energy: 0.3,
    flux: 0.25,
    centroid: 0.15,
    crest: 0.1,
    bass: 0.15,
    presence: 0.05
  },
  
  changeThresholds: {
    intensityChange: 0.2,
    durationChange: 0.3,
    stabilityChange: 0.25,
    timeWindow: 3000
  },
  
  emotionFeatures: {
    calm: {
      energyRange: [0.1, 0.4],
      fluxRange: [0.1, 0.3],
      centroidRange: [0.2, 0.5],
      bassRange: [0.2, 0.5],
      presenceRange: [0.1, 0.4],
      stabilityRange: [0.7, 1.0],
      transitionProbability: 0.6
    },
    energetic: {
      energyRange: [0.6, 1.0],
      fluxRange: [0.5, 1.0],
      centroidRange: [0.5, 0.8],
      bassRange: [0.6, 1.0],
      presenceRange: [0.5, 0.8],
      stabilityRange: [0.3, 0.6],
      transitionProbability: 0.8
    },
    melancholic: {
      energyRange: [0.2, 0.5],
      fluxRange: [0.1, 0.4],
      centroidRange: [0.1, 0.4],
      bassRange: [0.3, 0.6],
      presenceRange: [0.2, 0.5],
      stabilityRange: [0.6, 0.9],
      transitionProbability: 0.5
    },
    excited: {
      energyRange: [0.7, 1.0],
      fluxRange: [0.6, 1.0],
      centroidRange: [0.6, 0.9],
      bassRange: [0.7, 1.0],
      presenceRange: [0.6, 0.9],
      stabilityRange: [0.2, 0.5],
      transitionProbability: 0.7
    },
    focused: {
      energyRange: [0.4, 0.7],
      fluxRange: [0.3, 0.6],
      centroidRange: [0.4, 0.7],
      bassRange: [0.4, 0.7],
      presenceRange: [0.4, 0.7],
      stabilityRange: [0.5, 0.8],
      transitionProbability: 0.6
    },
    relaxed: {
      energyRange: [0.2, 0.5],
      fluxRange: [0.1, 0.4],
      centroidRange: [0.2, 0.5],
      bassRange: [0.2, 0.5],
      presenceRange: [0.1, 0.4],
      stabilityRange: [0.8, 1.0],
      transitionProbability: 0.4
    },
    intense: {
      energyRange: [0.8, 1.0],
      fluxRange: [0.7, 1.0],
      centroidRange: [0.7, 1.0],
      bassRange: [0.8, 1.0],
      presenceRange: [0.7, 1.0],
      stabilityRange: [0.1, 0.4],
      transitionProbability: 0.9
    }
  }
};

/**
 * æƒ…ç»ªå˜åŒ–æ£€æµ‹å™¨
 * åŸºäºéŸ³é¢‘ç‰¹å¾å’Œç”¨æˆ·äº¤äº’æ£€æµ‹æƒ…ç»ªå˜åŒ–
 */
export class EmotionChangeDetector {
  private config: EmotionDetectionConfig;
  private currentEmotion: EmotionState;
  private emotionStartTime: number = 0;
  private lastAudioFeatures: AudioFeatures | null = null;
  private emotionHistory: EmotionState[] = [];
  private isInitialized: boolean = false;
  private maxHistoryLength: number = 50;

  constructor(config?: Partial<EmotionDetectionConfig>) {
    this.config = { ...DEFAULT_EMOTION_DETECTION_CONFIG, ...config };
    
    // åˆå§‹åŒ–é»˜è®¤æƒ…ç»ªçŠ¶æ€
    this.currentEmotion = {
      type: 'calm',
      intensity: 0.5,
      confidence: 0.8,
      timestamp: Date.now(),
      duration: 0,
      stability: 0.8
    };
    
    this.emotionStartTime = Date.now();
    this.setupEventListeners();
  }

  /**
   * è®¾ç½®äº‹ä»¶ç›‘å¬å™¨
   */
  private setupEventListeners(): void {
    // ç›‘å¬éŸ³é¢‘ç‰¹å¾äº‹ä»¶
    UnifiedEventBus.on('audio', 'features', this.handleAudioFeatures.bind(this));
    
    // ç›‘å¬ç”¨æˆ·äº¤äº’äº‹ä»¶
    UnifiedEventBus.on('user', 'interaction', this.handleUserInteraction.bind(this));
    
    // ç›‘å¬å¤–éƒ¨æƒ…ç»ªäº‹ä»¶
    UnifiedEventBus.on('external', 'emotion', this.handleExternalEmotion.bind(this));
    
    console.log('ğŸ­ æƒ…ç»ªå˜åŒ–æ£€æµ‹å™¨äº‹ä»¶ç›‘å¬å™¨è®¾ç½®å®Œæˆ');
  }

  /**
   * å¤„ç†éŸ³é¢‘ç‰¹å¾äº‹ä»¶
   */
  private handleAudioFeatures(event: any): void {
    const { audioFeatures, timestamp } = event.data || {};
    if (!audioFeatures) return;

    this.processAudioFeatures(audioFeatures, timestamp || Date.now());
  }

  /**
   * å¤„ç†ç”¨æˆ·äº¤äº’äº‹ä»¶
   */
  private handleUserInteraction(event: any): void {
    const { type, intensity, timestamp } = event.data || {};
    if (!type || intensity === undefined) return;

    this.processUserInteraction(type, intensity, timestamp || Date.now());
  }

  /**
   * å¤„ç†å¤–éƒ¨æƒ…ç»ªäº‹ä»¶
   */
  private handleExternalEmotion(event: any): void {
    const { emotion, intensity, timestamp } = event.data || {};
    if (!emotion || intensity === undefined) return;

    this.processExternalEmotion(emotion, intensity, timestamp || Date.now());
  }

  /**
   * å¤„ç†éŸ³é¢‘ç‰¹å¾
   */
  private processAudioFeatures(audioFeatures: AudioFeatures, timestamp: number): void {
    if (!this.isInitialized) {
      this.initialize(timestamp);
    }

    // æ£€æµ‹æƒ…ç»ªå˜åŒ–
    const newEmotion = this.detectEmotionFromAudio(audioFeatures, timestamp);
    
    if (this.shouldTriggerEmotionChange(newEmotion)) {
      this.handleEmotionChange(newEmotion, 'audio', audioFeatures, timestamp);
    }

    // æ›´æ–°æœ€åéŸ³é¢‘ç‰¹å¾
    this.lastAudioFeatures = audioFeatures;
  }

  /**
   * å¤„ç†ç”¨æˆ·äº¤äº’
   */
  private processUserInteraction(type: string, intensity: number, timestamp: number): void {
    // åŸºäºç”¨æˆ·äº¤äº’è°ƒæ•´æƒ…ç»ª
    const adjustedEmotion = this.adjustEmotionFromUserInteraction(type, intensity);
    
    if (this.shouldTriggerEmotionChange(adjustedEmotion)) {
      this.handleEmotionChange(adjustedEmotion, 'user', undefined, timestamp);
    }
  }

  /**
   * å¤„ç†å¤–éƒ¨æƒ…ç»ª
   */
  private processExternalEmotion(emotion: string, intensity: number, timestamp: number): void {
    // åŸºäºå¤–éƒ¨è¾“å…¥è®¾ç½®æƒ…ç»ª
    const externalEmotion: EmotionState = {
      type: emotion as EmotionType,
      intensity: Math.max(0, Math.min(1, intensity)),
      confidence: 0.9,
      timestamp,
      duration: 0,
      stability: 0.7
    };
    
    if (this.shouldTriggerEmotionChange(externalEmotion)) {
      this.handleEmotionChange(externalEmotion, 'external', undefined, timestamp);
    }
  }

  /**
   * åˆå§‹åŒ–æ£€æµ‹å™¨
   */
  private initialize(timestamp: number): void {
    this.emotionStartTime = timestamp;
    this.isInitialized = true;
    console.log('ğŸ­ æƒ…ç»ªå˜åŒ–æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ');
  }

  /**
   * ä»éŸ³é¢‘ç‰¹å¾æ£€æµ‹æƒ…ç»ª
   */
  private detectEmotionFromAudio(audioFeatures: AudioFeatures, timestamp: number): EmotionState {
    const { energy, flux, centroid, crest, bass, presence } = audioFeatures;
    
    // è®¡ç®—æ¯ä¸ªæƒ…ç»ªçš„åŒ¹é…åº¦
    const emotionScores: Array<{ emotion: EmotionType; score: number }> = [];
    
    Object.entries(this.config.emotionFeatures).forEach(([emotionType, features]) => {
      const energyScore = this.calculateRangeMatch(energy, features.energyRange);
      const fluxScore = this.calculateRangeMatch(flux, features.fluxRange);
      const centroidScore = this.calculateRangeMatch(centroid, features.centroidRange);
      const bassScore = this.calculateRangeMatch(bass, features.bassRange);
      const presenceScore = this.calculateRangeMatch(presence, features.presenceRange);
      
      // åŠ æƒè®¡ç®—æ€»åˆ†
      const totalScore = 
        energyScore * this.config.audioFeatureWeights.energy +
        fluxScore * this.config.audioFeatureWeights.flux +
        centroidScore * this.config.audioFeatureWeights.centroid +
        bassScore * this.config.audioFeatureWeights.bass +
        presenceScore * this.config.audioFeatureWeights.presence;
      
      emotionScores.push({ emotion: emotionType as EmotionType, score: totalScore });
    });
    
    // é€‰æ‹©å¾—åˆ†æœ€é«˜çš„æƒ…ç»ª
    emotionScores.sort((a, b) => b.score - a.score);
    const bestEmotion = emotionScores[0];
    
    // è®¡ç®—æƒ…ç»ªå¼ºåº¦ï¼ˆåŸºäºéŸ³é¢‘ç‰¹å¾çš„æ•´ä½“å¼ºåº¦ï¼‰
    const overallIntensity = (energy + flux + bass) / 3;
    
    // è®¡ç®—ç½®ä¿¡åº¦
    const confidence = Math.min(1, bestEmotion.score * 1.2);
    
    // è®¡ç®—ç¨³å®šæ€§ï¼ˆåŸºäºå†å²æ•°æ®ï¼‰
    const stability = this.calculateEmotionStability(bestEmotion.emotion);
    
    return {
      type: bestEmotion.emotion,
      intensity: overallIntensity,
      confidence,
      timestamp,
      duration: 0,
      stability
    };
  }

  /**
   * åŸºäºç”¨æˆ·äº¤äº’è°ƒæ•´æƒ…ç»ª
   */
  private adjustEmotionFromUserInteraction(type: string, intensity: number): EmotionState {
    // æ ¹æ®äº¤äº’ç±»å‹è°ƒæ•´æƒ…ç»ª
    let adjustedType = this.currentEmotion.type;
    let adjustedIntensity = this.currentEmotion.intensity;
    
    switch (type) {
      case 'boost':
        adjustedIntensity = Math.min(1, adjustedIntensity + intensity * 0.3);
        if (adjustedIntensity > 0.7) adjustedType = 'energetic';
        break;
      case 'calm':
        adjustedIntensity = Math.max(0, adjustedIntensity - intensity * 0.3);
        if (adjustedIntensity < 0.3) adjustedType = 'calm';
        break;
      case 'focus':
        adjustedType = 'focused';
        adjustedIntensity = 0.6;
        break;
      case 'relax':
        adjustedType = 'relaxed';
        adjustedIntensity = 0.3;
        break;
    }
    
    return {
      type: adjustedType,
      intensity: adjustedIntensity,
      confidence: 0.8,
      timestamp: Date.now(),
      duration: 0,
      stability: this.currentEmotion.stability
    };
  }

  /**
   * è®¡ç®—èŒƒå›´åŒ¹é…åº¦
   */
  private calculateRangeMatch(value: number, range: [number, number]): number {
    const [min, max] = range;
    
    if (value < min) {
      return Math.max(0, 1 - (min - value) / min);
    } else if (value > max) {
      return Math.max(0, 1 - (value - max) / max);
    } else {
      return 1.0;
    }
  }

  /**
   * è®¡ç®—æƒ…ç»ªç¨³å®šæ€§
   */
  private calculateEmotionStability(emotionType: EmotionType): number {
    if (this.emotionHistory.length < 2) return 0.8;
    
    // è®¡ç®—æœ€è¿‘å‡ æ¬¡æƒ…ç»ªå˜åŒ–çš„é¢‘ç‡
    const recentChanges = this.emotionHistory
      .slice(-10)
      .filter(e => e.type !== emotionType).length;
    
    const stability = Math.max(0.1, 1 - (recentChanges / 10));
    return stability;
  }

  /**
   * åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘æƒ…ç»ªå˜åŒ–
   */
  private shouldTriggerEmotionChange(newEmotion: EmotionState): boolean {
    const { intensityChange, durationChange, stabilityChange, timeWindow } = this.config.changeThresholds;
    
    // æ£€æŸ¥å¼ºåº¦å˜åŒ–
    const intensityDiff = Math.abs(newEmotion.intensity - this.currentEmotion.intensity);
    if (intensityDiff < intensityChange) return false;
    
    // æ£€æŸ¥æŒç»­æ—¶é—´
    const currentDuration = Date.now() - this.emotionStartTime;
    if (currentDuration < timeWindow) return false;
    
    // æ£€æŸ¥æƒ…ç»ªç±»å‹å˜åŒ–
    if (newEmotion.type !== this.currentEmotion.type) return true;
    
    // æ£€æŸ¥ç¨³å®šæ€§å˜åŒ–
    const stabilityDiff = Math.abs(newEmotion.stability - this.currentEmotion.stability);
    if (stabilityDiff > stabilityChange) return true;
    
    return false;
  }

  /**
   * å¤„ç†æƒ…ç»ªå˜åŒ–
   */
  private handleEmotionChange(
    newEmotion: EmotionState, 
    trigger: 'audio' | 'user' | 'time' | 'external',
    audioFeatures?: AudioFeatures,
    timestamp?: number
  ): void {
    const oldEmotion = { ...this.currentEmotion };
    const changeTime = timestamp || Date.now();
    
    // è®¡ç®—å˜åŒ–å¹…åº¦
    const intensityChange = Math.abs(newEmotion.intensity - oldEmotion.intensity);
    const typeChange = newEmotion.type !== oldEmotion.type ? 1 : 0;
    const changeMagnitude = (intensityChange + typeChange) / 2;
    
    // è®¡ç®—å˜åŒ–ç½®ä¿¡åº¦
    const changeConfidence = (newEmotion.confidence + oldEmotion.confidence) / 2;
    
    // åˆ›å»ºæƒ…ç»ªå˜åŒ–äº‹ä»¶
    const emotionChangeEvent: EmotionChangeEvent = {
      type: 'emotion_change',
      fromEmotion: oldEmotion,
      toEmotion: newEmotion,
      changeMagnitude,
      confidence: changeConfidence,
      timestamp: changeTime,
      trigger,
      audioFeatures
    };
    
    // å‘å°„æƒ…ç»ªå˜åŒ–äº‹ä»¶
    UnifiedEventBus.emit({
      namespace: 'emotion',
      type: 'mood_change',
      timestamp: changeTime,
      data: {
        ...emotionChangeEvent,
        previousMood: oldEmotion,
        currentMood: newEmotion
      }
    });
    
    // æ›´æ–°å½“å‰æƒ…ç»ªçŠ¶æ€
    this.currentEmotion = {
      ...newEmotion,
      timestamp: changeTime,
      duration: 0
    };
    this.emotionStartTime = changeTime;
    
    // æ·»åŠ åˆ°å†å²è®°å½•
    this.addToHistory(oldEmotion);
    
    console.log(`ğŸ­ æƒ…ç»ªå˜åŒ–: ${oldEmotion.type} â†’ ${newEmotion.type} (è§¦å‘: ${trigger}, å¹…åº¦: ${changeMagnitude.toFixed(3)})`);
  }

  /**
   * æ·»åŠ åˆ°å†å²è®°å½•
   */
  private addToHistory(emotion: EmotionState): void {
    this.emotionHistory.push(emotion);
    
    if (this.emotionHistory.length > this.maxHistoryLength) {
      this.emotionHistory.shift();
    }
  }

  /**
   * è·å–å½“å‰æƒ…ç»ªçŠ¶æ€
   */
  public getCurrentEmotion(): EmotionState {
    return { ...this.currentEmotion };
  }

  /**
   * è·å–æƒ…ç»ªå†å²
   */
  public getEmotionHistory(): EmotionState[] {
    return [...this.emotionHistory];
  }

  /**
   * è·å–æ£€æµ‹å™¨çŠ¶æ€
   */
  public getStatus(): {
    isInitialized: boolean;
    currentEmotion: EmotionType;
    emotionStartTime: number;
    historyLength: number;
    lastAudioFeatures: boolean;
  } {
    return {
      isInitialized: this.isInitialized,
      currentEmotion: this.currentEmotion.type,
      emotionStartTime: this.emotionStartTime,
      historyLength: this.emotionHistory.length,
      lastAudioFeatures: !!this.lastAudioFeatures
    };
  }

  /**
   * æ›´æ–°é…ç½®
   */
  public updateConfig(newConfig: Partial<EmotionDetectionConfig>): void {
    this.config = { ...this.config, ...newConfig };
    console.log('ğŸ­ æƒ…ç»ªæ£€æµ‹é…ç½®å·²æ›´æ–°');
  }

  /**
   * é”€æ¯æ£€æµ‹å™¨
   */
  public destroy(): void {
    // ç§»é™¤äº‹ä»¶ç›‘å¬å™¨
    UnifiedEventBus.off('audio', 'features', this.handleAudioFeatures.bind(this));
    UnifiedEventBus.off('user', 'interaction', this.handleUserInteraction.bind(this));
    UnifiedEventBus.off('external', 'emotion', this.handleExternalEmotion.bind(this));
    
    console.log('ğŸ§¹ æƒ…ç»ªå˜åŒ–æ£€æµ‹å™¨å·²é”€æ¯');
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const emotionChangeDetector = new EmotionChangeDetector();
