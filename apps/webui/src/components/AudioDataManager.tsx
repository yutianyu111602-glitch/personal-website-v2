import React, { useEffect, useRef, useCallback, useState } from 'react';

// éŸ³é¢‘é¢‘è°±æ•°æ®ç±»å‹
export interface AudioSpectrumData {
  frequency: Uint8Array;  // é¢‘ç‡æ•°æ® (0-255)
  timeDomain: Uint8Array; // æ—¶åŸŸæ•°æ® (0-255)
  rms: number;            // å‡æ–¹æ ¹å€¼ (éŸ³é‡)
  centroid: number;       // é¢‘è°±è´¨å¿ƒ (éŸ³è‰²ç‰¹å¾)
  flux: number;           // é¢‘è°±é€šé‡ (å˜åŒ–ç‡)
  timestamp: number;      // æ—¶é—´æˆ³
}

// éŸ³é¢‘åˆ†æå™¨é…ç½®
export interface AudioAnalyzerConfig {
  fftSize: number;        // FFTå¤§å° (256, 512, 1024, 2048)
  smoothingTimeConstant: number; // å¹³æ»‘æ—¶é—´å¸¸æ•° (0-1)
  minDecibels: number;    // æœ€å°åˆ†è´å€¼
  maxDecibels: number;    // æœ€å¤§åˆ†è´å€¼
  sampleRate: number;     // é‡‡æ ·ç‡
}

// äº‹ä»¶å›è°ƒç±»å‹
export interface AudioDataCallbacks {
  onSpectrumUpdate?: (data: AudioSpectrumData) => void;
  onAudioStart?: () => void;
  onAudioStop?: () => void;
  onError?: (error: string) => void;
}

// éŸ³é¢‘æ•°æ®ç®¡ç†å™¨å±æ€§
export interface AudioDataManagerProps {
  audioElement: HTMLAudioElement | null;
  config?: Partial<AudioAnalyzerConfig>;
  callbacks?: AudioDataCallbacks;
  enabled?: boolean;
}

/**
 * éŸ³é¢‘æ•°æ®ç®¡ç†å™¨
 * è´Ÿè´£ä»HTMLAudioElementæå–å®æ—¶éŸ³é¢‘æ•°æ®ï¼Œå¹¶æä¾›ç»™å¯è§†åŒ–æ¨¡å—
 * 
 * æ ¸å¿ƒåŠŸèƒ½ï¼š
 * - ğŸµ å®æ—¶éŸ³é¢‘é¢‘è°±åˆ†æ
 * - ğŸ“Š éŸ³é¢‘ç‰¹å¾æå– (RMS, è´¨å¿ƒ, é€šé‡)
 * - ğŸ”„ æ•°æ®æµç®¡ç†
 * - ğŸ¨ å¯è§†åŒ–æ•°æ®æ ¼å¼åŒ–
 */
export const AudioDataManager: React.FC<AudioDataManagerProps> = ({
  audioElement,
  config = {},
  callbacks = {},
  enabled = true
}) => {
  // çŠ¶æ€ç®¡ç†
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [audioContext, setAudioContext] = useState<AudioContext | null>(null);
  const [analyser, setAnalyser] = useState<AnalyserNode | null>(null);
  const [source, setSource] = useState<MediaElementAudioSourceNode | null>(null);
  // const [error, setError] = useState<string | null>(null); // æœªä½¿ç”¨

  // å¼•ç”¨
  const animationFrameRef = useRef<number | null>(null);
  const lastSpectrumDataRef = useRef<AudioSpectrumData | null>(null);

  // é»˜è®¤é…ç½®
  const defaultConfig: AudioAnalyzerConfig = {
    fftSize: 256,
    smoothingTimeConstant: 0.8,
    minDecibels: -90,
    maxDecibels: -10,
    sampleRate: 44100,
    ...config
  };

  // åˆå§‹åŒ–éŸ³é¢‘åˆ†æå™¨
  const initializeAnalyzer = useCallback(async () => {
    if (!audioElement || !enabled) return;

    try {
      // åˆ›å»ºAudioContext
      const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
      const newAudioContext = new AudioContextClass();
      
      // åˆ›å»ºåˆ†æå™¨èŠ‚ç‚¹
      const newAnalyser = newAudioContext.createAnalyser();
      newAnalyser.fftSize = defaultConfig.fftSize;
      newAnalyser.smoothingTimeConstant = defaultConfig.smoothingTimeConstant;
      newAnalyser.minDecibels = defaultConfig.minDecibels;
      newAnalyser.maxDecibels = defaultConfig.maxDecibels;

      // åˆ›å»ºéŸ³é¢‘æº
      const newSource = newAudioContext.createMediaElementSource(audioElement);
      
      // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
      newSource.connect(newAnalyser);
      newAnalyser.connect(newAudioContext.destination);

      // ä¿å­˜å¼•ç”¨
      setAudioContext(newAudioContext);
      setAnalyser(newAnalyser);
      setSource(newSource);
      // setError(null); // æœªä½¿ç”¨

      console.log('ğŸµ éŸ³é¢‘åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ');
      callbacks.onAudioStart?.();

    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'æœªçŸ¥é”™è¯¯';
      // setError(errorMessage); // æœªä½¿ç”¨
      callbacks.onError?.(errorMessage);
      console.error('âŒ éŸ³é¢‘åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥:', err);
    }
  }, [audioElement, enabled, defaultConfig, callbacks]);

  // æ¸…ç†éŸ³é¢‘åˆ†æå™¨
  const cleanupAnalyzer = useCallback(() => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    if (source) {
      source.disconnect();
      setSource(null);
    }

    if (analyser) {
      analyser.disconnect();
      setAnalyser(null);
    }

    // é˜²é‡å¤å…³é—­ AudioContext
    try {
      if (audioContext && audioContext.state !== 'closed') {
        audioContext.close().catch(() => {});
      }
    } finally {
      setAudioContext(null);
    }

    setIsAnalyzing(false);
    console.log('ğŸ§¹ éŸ³é¢‘åˆ†æå™¨å·²æ¸…ç†');
  }, [source, analyser, audioContext]);

  // å¼€å§‹éŸ³é¢‘åˆ†æ
  const startAnalysis = useCallback(() => {
    if (!analyser || isAnalyzing) return;

    setIsAnalyzing(true);
    console.log('ğŸµ å¼€å§‹éŸ³é¢‘åˆ†æ');

    const analyzeAudio = () => {
      if (!analyser || !isAnalyzing) return;

      try {
        // è·å–é¢‘ç‡æ•°æ®
        const frequencyData = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(frequencyData);

        // è·å–æ—¶åŸŸæ•°æ®
        const timeDomainData = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteTimeDomainData(timeDomainData);

        // è®¡ç®—éŸ³é¢‘ç‰¹å¾
        const rms = calculateRMS(timeDomainData);
        const centroid = calculateCentroid(frequencyData);
        const flux = calculateFlux(frequencyData, lastSpectrumDataRef.current?.frequency);

        // åˆ›å»ºé¢‘è°±æ•°æ®å¯¹è±¡
        const spectrumData: AudioSpectrumData = {
          frequency: frequencyData,
          timeDomain: timeDomainData,
          rms,
          centroid,
          flux,
          timestamp: Date.now()
        };

        // ä¿å­˜å½“å‰æ•°æ®ç”¨äºä¸‹æ¬¡è®¡ç®—
        lastSpectrumDataRef.current = spectrumData;

        // è§¦å‘å›è°ƒ
        callbacks.onSpectrumUpdate?.(spectrumData);

        // ç»§ç»­åˆ†æ
        animationFrameRef.current = requestAnimationFrame(analyzeAudio);

      } catch (err) {
        console.error('âŒ éŸ³é¢‘åˆ†æé”™è¯¯:', err);
        setIsAnalyzing(false);
      }
    };

    // å¼€å§‹åˆ†æå¾ªç¯
    analyzeAudio();

  }, [analyser, isAnalyzing, callbacks]);

  // åœæ­¢éŸ³é¢‘åˆ†æ
  const stopAnalysis = useCallback(() => {
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    setIsAnalyzing(false);
    console.log('â¸ï¸ éŸ³é¢‘åˆ†æå·²åœæ­¢');
  }, []);

  // è®¡ç®—RMS (å‡æ–¹æ ¹å€¼)
  const calculateRMS = useCallback((timeDomainData: Uint8Array): number => {
    let sum = 0;
    for (let i = 0; i < timeDomainData.length; i++) {
      const sample = (timeDomainData[i] - 128) / 128; // è½¬æ¢ä¸º-1åˆ°1èŒƒå›´
      sum += sample * sample;
    }
    return Math.sqrt(sum / timeDomainData.length);
  }, []);

  // è®¡ç®—é¢‘è°±è´¨å¿ƒ
  const calculateCentroid = useCallback((frequencyData: Uint8Array): number => {
    let weightedSum = 0;
    let totalSum = 0;
    
    for (let i = 0; i < frequencyData.length; i++) {
      const magnitude = frequencyData[i] / 255; // å½’ä¸€åŒ–åˆ°0-1
      const frequency = i * defaultConfig.sampleRate / (2 * frequencyData.length);
      
      weightedSum += magnitude * frequency;
      totalSum += magnitude;
    }
    
    return totalSum > 0 ? weightedSum / totalSum : 0;
  }, [defaultConfig.sampleRate]);

  // è®¡ç®—é¢‘è°±é€šé‡
  const calculateFlux = useCallback((currentFreq: Uint8Array, previousFreq: Uint8Array | undefined): number => {
    if (!previousFreq || currentFreq.length !== previousFreq.length) return 0;
    
    let flux = 0;
    for (let i = 0; i < currentFreq.length; i++) {
      const diff = currentFreq[i] - previousFreq[i];
      flux += diff * diff;
    }
    
    return Math.sqrt(flux / currentFreq.length);
  }, []);

  // ç›‘å¬éŸ³é¢‘å…ƒç´ å˜åŒ–
  useEffect(() => {
    if (audioElement && enabled) {
      initializeAnalyzer();
    } else {
      cleanupAnalyzer();
    }

    return () => {
      cleanupAnalyzer();
    };
  }, [audioElement, enabled, initializeAnalyzer, cleanupAnalyzer]);

  // ç›‘å¬åˆ†æçŠ¶æ€å˜åŒ–
  useEffect(() => {
    if (isAnalyzing) {
      startAnalysis();
    } else {
      stopAnalysis();
    }
  }, [isAnalyzing, startAnalysis, stopAnalysis]);

  // ç›‘å¬éŸ³é¢‘æ’­æ”¾çŠ¶æ€
  useEffect(() => {
    if (!audioElement) return;

    const handlePlay = () => {
      if (enabled && !isAnalyzing) {
        startAnalysis();
      }
    };

    const handlePause = () => {
      if (isAnalyzing) {
        stopAnalysis();
      }
    };

    const handleEnded = () => {
      stopAnalysis();
      callbacks.onAudioStop?.();
    };

    audioElement.addEventListener('play', handlePlay);
    audioElement.addEventListener('pause', handlePause);
    audioElement.addEventListener('ended', handleEnded);

    return () => {
      audioElement.removeEventListener('play', handlePlay);
      audioElement.removeEventListener('pause', handlePause);
      audioElement.removeEventListener('ended', handleEnded);
    };
  }, [audioElement, enabled, isAnalyzing, startAnalysis, stopAnalysis, callbacks]);

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  useEffect(() => {
    return () => {
      cleanupAnalyzer();
    };
  }, [cleanupAnalyzer]);

  // è¿™ä¸ªç»„ä»¶ä¸éœ€è¦æ¸²æŸ“UIï¼Œåªè´Ÿè´£éŸ³é¢‘æ•°æ®å¤„ç†
  return null;
};

export default AudioDataManager;
